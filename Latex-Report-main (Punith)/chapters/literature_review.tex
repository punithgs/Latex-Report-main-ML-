\chapter{Literature Review}
\subsection{Paper 1} \textbf{Title}: "Real-Time Hand Motion Recognition Using Hidden Markov Models and Convolutional Neural Networks" \\
\textbf{Author}: Illuri \\
\textbf{Publication Details}:Journal/Conference: Proceedings of the IEEE International Conference on Biomedical Engineering (ICBE)
 \\
\textbf{Year}: 2022 \\
\textbf{Explanation}: Illuri et al.'s study introduces a novel approach to real-time hand motion recognition by combining Hidden Markov Models (HMMs) with Convolutional Neural Networks (CNNs). By generating a 3-D representation of the angular relationship between biological components and encoding it with HMMs, the researchers developed a robust transition gesture model. The experimental results showcase the system's ability to accurately recognize hand postures with minimal inaccuracies, making it suitable for real-time implementations. Furthermore, the superior performance of CNNs compared to baseline models highlights the effectiveness of leveraging deep learning techniques for this task. However, the discrepancy between the validation and training dataset accuracies suggests potential issues in the data that warrant further investigation.


\subsection{Paper 2} \textbf{Title}: "Accelerated Hand Sign Recognition Using Convolutional Neural Networks on TCPA Overlay for Embedded Systems"
 \\
\textbf{Author}:Heidorn et al.
 \\
\textbf{Publication Details}:Journal/Conference: IEEE Embedded Systems Letters
 \\
\textbf{Year}: 2021 \\
\textbf{Explanation}: Heidorn et al.'s work underscores the impact of deep learning on computer vision, particularly in the realm of hand sign recognition. Their implementation of a CNN-based hand sign recognition system accelerated on a TCPA (Tensor Processing Cluster Array) demonstrates the potential of leveraging high-end accelerators like GPUs and FPGAs in embedded systems. By prototypically implementing TCPA as an overlay on a Xilinx Zynq System-on-a-Chip (SoC), the researchers achieved remarkable speed-ups compared to traditional ARM Cortex-A9 processors. This research signifies a significant advancement in the field of embedded
systems and opens avenues for further exploration of CNN acceleration techniques for real-time applications.

\subsection{Paper 3} \textbf{Title}: "Bridging the Communication Gap: A Comparative Analysis of Machine Learning Algorithms for Sign Language Recognition"
 \\
\textbf{Author}:Pala et al.
 \\
\textbf{Publication Details}:Journal/Conference: ACM Transactions on Accessible Computing
 \\
\textbf{Year}: 2021 \\
\textbf{Explanation}: Pala et al.'s research addresses the vital need for communication bridges between the deaf and voiceless communities and the wider population. By designing a system to interpret sign language, they aim to facilitate interaction between these groups. The study compares the effectiveness of KNN, SVM, and CNN algorithms for sign language recognition, considering the variability in hand gestures. Their findings indicate that CNN achieves the highest accuracy of 98.49%, outperforming KNN (93.83%) and SVM (88.89%). However, the long training time due to the large dataset poses a challenge. Implementing big data processing methods could alleviate this issue, making the system more efficient and accessible for real-world deployment.

\subsection{Paper 4} \textbf{Title}: "Prediction-and-Verification Segmentation Scheme for Hand Sign Recognition in Attention Images"
 \\
\textbf{Author} Cui and Weng
 \\
\textbf{Publication Details}:Journal/Conference: IEEE Transactions on Pattern Analysis and Machine Intelligence
 \\
\textbf{Year}: 2021 \\
\textbf{Explanation}: Cui and Weng's segmentation scheme for hand sign recognition in attention images represents a significant advancement in the field, particularly in handling multiple deformable objects in complex backgrounds. The scheme's efficiency is highlighted by its ability to leverage past knowledge through a prediction-and-verification approach. By testing the system on sequences of intensity images representing hand signs, the researchers achieved impressive results, with a 95% correct segmentation rate and only a 3% false rejection rate. This study lays a solid foundation for further research in segmentation techniques for complex visual tasks.

\subsection{Paper 5} \textbf{Title}:  "Real-Time Sign Recognition Architecture Using Data Gloves and Accelerometers"
 \\
\textbf{Author} Ibarguren et al.
 \\
\textbf{Publication Details}Journal/Conference: IEEE Transactions on Human-Machine Systems
 \\
\textbf{Year}: 2020 \\
\textbf{Explanation}: Ibarguren et al.'s work presents a real-time sign recognition architecture integrating gesture and movement recognition using data gloves and accelerometers. The architecture operates in two tiers, segmentation and classification, to address the challenges of real-time processing. Despite efforts to handle issues like sensor noise and simplify training, segmentation problems persist, particularly when there are slight hand movements between signs or corrections during signing. To improve recognition rates, the authors suggest the creation of more complex classifiers. This research contributes valuable insights into the development of effective sign recognition systems for enhanced human-computerÂ interaction.

}
